#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆ: é¿å…æ•°æ®æ³„éœ²çš„æ­£ç¡®æµç¨‹

å…³é”®æ”¹è¿›:
1. å…ˆåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
2. ä»…åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œç‰¹å¾é€‰æ‹©
3. åœ¨ç‹¬ç«‹çš„æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹

è¿™æ ·å¯ä»¥å¾—åˆ°çœŸå®å¯é çš„æ€§èƒ½ä¼°è®¡
"""

import os
import sys
import pandas as pd
import numpy as np
import gzip
import re
from pathlib import Path
from sklearn.model_selection import train_test_split

from modules.step3_differential_expression import DifferentialExpressionAnalyzer
from modules.step4_feature_selection import FeatureSelector
from modules.step5_classification import BiomarkerClassifier
from modules.step6_visualization import BiomarkerVisualizer

import config


def parse_gtf_for_lncrnas(gtf_file: str) -> set:
    """è§£æGTFæ–‡ä»¶æå–lncRNA"""
    print("è§£æGTFæ–‡ä»¶...")
    lncrna_genes = set()

    with gzip.open(gtf_file, 'rt') as f:
        for line in f:
            if line.startswith('#'):
                continue
            fields = line.strip().split('\t')
            if len(fields) < 9 or fields[2] != 'gene':
                continue

            attributes = fields[8]
            gene_type_match = re.search(r'gene_type "([^"]+)"', attributes)
            gene_id_match = re.search(r'gene_id "ENSG\d+\.?\d*"', attributes)

            if gene_type_match and gene_id_match and gene_type_match.group(1) == 'lncRNA':
                gene_id = re.search(r'ENSG\d+', gene_id_match.group(0)).group(0)
                lncrna_genes.add(gene_id)

    print(f"âœ“ æå– {len(lncrna_genes):,} ä¸ªlncRNA")
    return lncrna_genes


def load_and_prepare_data(expr_file, clinical_file, lncrna_genes):
    """åŠ è½½å¹¶å‡†å¤‡æ•°æ®"""
    print("\nåŠ è½½å’Œå‡†å¤‡æ•°æ®...")

    # åŠ è½½è¡¨è¾¾çŸ©é˜µ
    print("  - åŠ è½½è¡¨è¾¾çŸ©é˜µ...")
    expr_df = pd.read_csv(expr_file, sep='\t', compression='gzip', index_col=0)
    expr_df.index = expr_df.index.str.split('.').str[0]

    # è¿‡æ»¤lncRNA
    lncrna_present = [gid for gid in lncrna_genes if gid in expr_df.index]
    expr_lncrna = expr_df.loc[lncrna_present]
    print(f"  âœ“ è¡¨è¾¾çŸ©é˜µ: {expr_lncrna.shape[0]:,} lncRNA Ã— {expr_lncrna.shape[1]:,} æ ·æœ¬")

    # åŠ è½½ä¸´åºŠæ•°æ®
    print("  - è§£ææ ·æœ¬ç±»å‹...")
    clinical_df = pd.read_csv(clinical_file, sep='\t', compression='gzip')
    sample_id_col = clinical_df.columns[0]

    tumor_samples = []
    normal_samples = []

    for sid in clinical_df[sample_id_col].values:
        if isinstance(sid, str) and '-' in sid:
            parts = sid.split('-')
            if len(parts) >= 4:
                code = parts[3][:2]
                if code in ['01', '02', '03', '04', '05', '06', '07', '08', '09']:
                    tumor_samples.append(sid)
                elif code in ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19']:
                    normal_samples.append(sid)

    # åŒ¹é…æ ·æœ¬
    common_tumor = [s for s in tumor_samples if s in expr_lncrna.columns]
    common_normal = [s for s in normal_samples if s in expr_lncrna.columns]

    print(f"  âœ“ åŒ¹é…æ ·æœ¬: {len(common_tumor)} è‚¿ç˜¤ + {len(common_normal)} æ­£å¸¸")

    # åˆ›å»ºæ•°æ®æ¡†
    tumor_data = expr_lncrna[common_tumor]
    normal_data = expr_lncrna[common_normal]

    # è¿‡æ»¤ä½è¡¨è¾¾
    print("  - è¿‡æ»¤ä½è¡¨è¾¾lncRNA...")
    mean_expr = pd.concat([tumor_data, normal_data], axis=1).mean(axis=1)
    expr_filtered = pd.concat([tumor_data, normal_data], axis=1).loc[mean_expr >= 1.0]

    tumor_data = tumor_data.loc[expr_filtered.index]
    normal_data = normal_data.loc[expr_filtered.index]

    print(f"  âœ“ ä¿ç•™ {len(tumor_data)} ä¸ªè¡¨è¾¾çš„lncRNA")

    return tumor_data, normal_data


def main():
    """ä¸»æµç¨‹ - é¿å…æ•°æ®æ³„éœ²"""

    print("\n" + "=" * 70)
    print(" " * 15 + "lncRNAç”Ÿç‰©æ ‡å¿—ç‰©å‘ç°ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print(" " * 10 + "é¿å…æ•°æ®æ³„éœ²çš„æ­£ç¡®æµç¨‹")
    print("=" * 70)

    # 1. åŠ è½½æ•°æ®
    base_dir = Path(config.PROJECT_DIR)
    expr_file = base_dir / "TCGA-LIHC.star_counts.tsv.gz"
    clinical_file = base_dir / "TCGA-LIHC.clinical.tsv.gz"
    gtf_file = base_dir / "gencode.v36.long_noncoding_RNAs.gtf.gz"

    lncrna_genes = parse_gtf_for_lncrnas(str(gtf_file))
    tumor_data, normal_data = load_and_prepare_data(str(expr_file), str(clinical_file), lncrna_genes)

    # 2. â­ å…³é”®æ”¹è¿›ï¼šå…ˆåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    print("\n" + "=" * 70)
    print("å…³é”®æ­¥éª¤ï¼šå…ˆåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
    print("=" * 70)

    # åˆå¹¶æ•°æ®
    all_data = pd.concat([tumor_data, normal_data], axis=1)  # genes x samples
    all_labels = [1] * tumor_data.shape[1] + [0] * normal_data.shape[1]  # å¯¹åº”æ ·æœ¬çš„æ ‡ç­¾

    # åˆ’åˆ†æ•°æ® (åˆ†å±‚é‡‡æ ·)
    X_train, X_test, y_train, y_test = train_test_split(
        all_data.T,  # è½¬ç½®ä¸ºæ ·æœ¬Ã—ç‰¹å¾
        all_labels,
        test_size=0.2,
        random_state=config.RANDOM_STATE,
        stratify=all_labels  # ä¿æŒç±»åˆ«æ¯”ä¾‹
    )

    print(f"\næ•°æ®åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(y_train)} æ ·æœ¬ (è‚¿ç˜¤: {sum(y_train)}, æ­£å¸¸: {len(y_train)-sum(y_train)})")
    print(f"  æµ‹è¯•é›†: {len(y_test)} æ ·æœ¬ (è‚¿ç˜¤: {sum(y_test)}, æ­£å¸¸: {len(y_test)-sum(y_test)})")

    # ä¿å­˜æ ·æœ¬å
    train_sample_names = X_train.index.tolist()
    test_sample_names = X_test.index.tolist()

    # è½¬æ¢å›åŸºå› Ã—æ ·æœ¬æ ¼å¼
    train_tumor_samples = [train_sample_names[i] for i in range(len(train_sample_names)) if y_train[i] == 1]
    train_normal_samples = [train_sample_names[i] for i in range(len(train_sample_names)) if y_train[i] == 0]
    test_tumor_samples = [test_sample_names[i] for i in range(len(test_sample_names)) if y_test[i] == 1]
    test_normal_samples = [test_sample_names[i] for i in range(len(test_sample_names)) if y_test[i] == 0]

    train_tumor = X_train.T[train_tumor_samples]
    train_normal = X_train.T[train_normal_samples]
    test_tumor = X_test.T[test_tumor_samples]
    test_normal = X_test.T[test_normal_samples]

    # 3. å·®å¼‚è¡¨è¾¾åˆ†æï¼ˆä»…åœ¨è®­ç»ƒé›†ä¸Šï¼‰
    print("\n" + "=" * 70)
    print("æ­¥éª¤1: å·®å¼‚è¡¨è¾¾åˆ†æï¼ˆä»…è®­ç»ƒé›†ï¼‰")
    print("=" * 70)

    de_analyzer = DifferentialExpressionAnalyzer(verbose=True)
    de_results = de_analyzer.identify_differential_expression(
        train_tumor, train_normal,
        log2fc_threshold=1.0,
        fdr_threshold=0.05
    )

    significant_genes = de_results[de_results['significant']]['gene_id'].tolist()
    print(f"\nâœ“ è®­ç»ƒé›†ä¸­å‘ç° {len(significant_genes)} ä¸ªæ˜¾è‘—å·®å¼‚lncRNA")

    # 4. ç‰¹å¾é€‰æ‹©ï¼ˆä»…åœ¨è®­ç»ƒé›†ä¸Šï¼‰â­ å…³é”®
    print("\n" + "=" * 70)
    print("æ­¥éª¤2: ç‰¹å¾é€‰æ‹©ï¼ˆä»…è®­ç»ƒé›†ï¼‰")
    print("=" * 70)

    feature_selector = FeatureSelector(verbose=True)
    selected_biomarkers, _ = feature_selector.run_feature_selection_pipeline(
        train_tumor, train_normal,
        de_genes=significant_genes,
        n_features=20,
        method='lasso'
    )

    print(f"\nâœ“ é€‰æ‹© {len(selected_biomarkers)} ä¸ªç”Ÿç‰©æ ‡å¿—ç‰©")

    # 5. è®­ç»ƒæ¨¡å‹ï¼ˆä»…ç”¨è®­ç»ƒé›†ï¼‰
    print("\n" + "=" * 70)
    print("æ­¥éª¤3: è®­ç»ƒSVMæ¨¡å‹ï¼ˆä»…è®­ç»ƒé›†ï¼‰")
    print("=" * 70)

    # æå–é€‰æ‹©çš„ç‰¹å¾
    train_tumor_selected = train_tumor.loc[selected_biomarkers]
    train_normal_selected = train_normal.loc[selected_biomarkers]

    classifier = BiomarkerClassifier(classifier_type='svm', verbose=True)
    classifier.prepare_training_data(train_tumor_selected, train_normal_selected)

    # è®­ç»ƒSVM
    classifier.train_svm()

    # 6. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆå…³é”®æ­¥éª¤ï¼‰
    print("\n" + "=" * 70)
    print("æ­¥éª¤4: åœ¨ç‹¬ç«‹çš„æµ‹è¯•é›†ä¸Šè¯„ä¼°")
    print("=" * 70)

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_tumor_selected = test_tumor.loc[selected_biomarkers]
    test_normal_selected = test_normal.loc[selected_biomarkers]

    # åˆå¹¶æµ‹è¯•æ•°æ®
    test_data = pd.concat([test_tumor_selected, test_normal_selected], axis=1)
    test_labels = np.array([1] * len(test_tumor_selected.columns) + [0] * len(test_normal_selected.columns))

    # æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡é‡ï¼‰
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()

    # åœ¨è®­ç»ƒé›†ä¸Šfit
    train_combined = pd.concat([train_tumor_selected, train_normal_selected], axis=1)
    scaler.fit(train_combined.T.values)

    # è½¬æ¢æµ‹è¯•æ•°æ®
    test_scaled = scaler.transform(test_data.T.values)

    # é¢„æµ‹
    y_pred = classifier.model.predict(test_scaled)
    y_pred_proba = classifier.model.predict_proba(test_scaled)[:, 1]

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix

    accuracy = accuracy_score(test_labels, y_pred)
    precision = precision_score(test_labels, y_pred, zero_division=0)
    recall = recall_score(test_labels, y_pred, zero_division=0)
    f1 = f1_score(test_labels, y_pred, zero_division=0)

    # ROCå’ŒAUC
    fpr, tpr, _ = roc_curve(test_labels, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(test_labels, y_pred)
    tn, fp, fn, tp = cm.ravel()

    print(f"\nğŸ“Š æµ‹è¯•é›†æ€§èƒ½ (çœŸå®æ€§èƒ½):")
    print(f"  - å‡†ç¡®ç‡: {accuracy:.3f}")
    print(f"  - ç²¾ç¡®ç‡: {precision:.3f}")
    print(f"  - çµæ•åº¦: {recall:.3f}")
    print(f"  - ç‰¹å¼‚åº¦: {tn/(tn+fp):.3f}")
    print(f"  - F1åˆ†æ•°: {f1:.3f}")
    print(f"  - AUC-ROC: {roc_auc:.3f}")

    print(f"\næ··æ·†çŸ©é˜µ:")
    print(f"                é¢„æµ‹æ­£å¸¸    é¢„æµ‹è‚¿ç˜¤")
    print(f"  å®é™…æ­£å¸¸       {tn:3d}        {fp:3d}")
    print(f"  å®é™…è‚¿ç˜¤       {fn:3d}        {tp:3d}")

    # 7. äº¤å‰éªŒè¯ï¼ˆä»…åœ¨è®­ç»ƒé›†ä¸Šï¼‰
    print("\n" + "=" * 70)
    print("æ­¥éª¤5: äº¤å‰éªŒè¯ï¼ˆä»…åœ¨è®­ç»ƒé›†ä¸Šï¼‰")
    print("=" * 70)

    from sklearn.model_selection import cross_val_score, StratifiedKFold
    from sklearn.svm import SVC
    from sklearn.preprocessing import StandardScaler

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train_full = train_combined.T.values
    y_train_full = np.array([1] * len(train_tumor_selected.columns) + [0] * len(train_normal_selected.columns))

    # æ ‡å‡†åŒ–
    scaler_cv = StandardScaler()
    X_train_scaled = scaler_cv.fit_transform(X_train_full)

    # äº¤å‰éªŒè¯
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=config.RANDOM_STATE)
    svm_cv = SVC(C=1.0, kernel='rbf', gamma='scale', class_weight='balanced', random_state=config.RANDOM_STATE)

    cv_scores = cross_val_score(svm_cv, X_train_scaled, y_train_full, cv=cv, scoring='accuracy')

    print(f"\nâœ“ 5æŠ˜äº¤å‰éªŒè¯ç»“æœ:")
    print(f"  - å„æŠ˜å‡†ç¡®ç‡: {[f'{s:.3f}' for s in cv_scores]}")
    print(f"  - å¹³å‡å‡†ç¡®ç‡: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

    # 8. æ€»ç»“
    print("\n" + "=" * 70)
    print("æ€»ç»“: çœŸå®æ€§èƒ½ vs è¿‡æ‹Ÿåˆæ€§èƒ½")
    print("=" * 70)

    print(f"\nâŒ ä¹‹å‰çš„é”™è¯¯æµç¨‹ï¼ˆæ•°æ®æ³„éœ²ï¼‰:")
    print(f"   - æµ‹è¯•é›†å‡†ç¡®ç‡: 100% (è™šå‡çš„å®Œç¾)")
    print(f"   - AUC: 1.000 (ä¸ç°å®)")
    print(f"   - åŸå› : ç‰¹å¾é€‰æ‹©æ—¶çœ‹åˆ°äº†æµ‹è¯•é›†")

    print(f"\nâœ… ä¿®å¤åçš„æ­£ç¡®æµç¨‹:")
    print(f"   - æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.1%}")
    print(f"   - AUC: {roc_auc:.3f}")
    print(f"   - äº¤å‰éªŒè¯: {cv_scores.mean():.1%} Â± {cv_scores.std():.3f}")
    print(f"   - åŸå› : æµ‹è¯•é›†å®Œå…¨ç‹¬ç«‹")

    print(f"\nğŸ’¡ æ€§èƒ½è§£è¯»:")
    if accuracy > 0.95:
        print(f"   - æ€§èƒ½ä¼˜ç§€ï¼Œä½†éœ€è¦éªŒè¯")
        print(f"   - å»ºè®®: åœ¨ç‹¬ç«‹æ•°æ®é›†ä¸ŠéªŒè¯")
    elif accuracy > 0.85:
        print(f"   - æ€§èƒ½è‰¯å¥½ï¼Œç»“æœå¯ä¿¡")
    else:
        print(f"   - æ€§èƒ½ä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–ç‰¹å¾æˆ–æ¨¡å‹")

    print("\n" + "=" * 70 + "\n")


if __name__ == "__main__":
    main()
